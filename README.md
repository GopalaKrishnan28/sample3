# Phi-3.5 Mini Instruct GGUF (Q4_K_M)

This repository includes the `Phi-3.5-mini-instruct-Q4_K_M.gguf` model file for use with `llama.cpp` or compatible Python libraries like `llama-cpp-python`.

## ðŸ“Œ Model Info

- **Base model**: [microsoft/Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct)
- **Quantized by**: [bartowski](https://huggingface.co/bartowski)
- **Quantization format**: GGUF Q4_K_M (llama.cpp compatible)
- **License**: MIT License

## ðŸ“¥ Download Instructions

You can download the model directly from Hugging Face:

```bash
huggingface-cli download bartowski/Phi-3.5-mini-instruct-GGUF --include "Phi-3.5-mini-instruct-Q4_K_M.gguf" --local-dir .
